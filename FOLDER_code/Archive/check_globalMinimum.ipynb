{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making sure the global minimum is `[-2.333, -4.333]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_AGENTS = 4\n",
    "\n",
    "\n",
    "P = np.array(\n",
    "    [ [[0.2, 0.1],\n",
    "        [0.1, 0.2]],\n",
    "\n",
    "      [[0.4, 0.1],\n",
    "        [0.2, 0.4]],\n",
    "\n",
    "      [[0.3, 0.1],\n",
    "        [0.1, 0.2]],\n",
    "\n",
    "      [[0.5, 0.1],\n",
    "        [0.1, 0.2]],   \n",
    "          ]\n",
    ")\n",
    "\n",
    "b = np.array(\n",
    "    [ [[1],\n",
    "        [8]],\n",
    "\n",
    "      [[1],\n",
    "        [1]],\n",
    "\n",
    "      [[3],\n",
    "        [1]],\n",
    "\n",
    "      [[5],\n",
    "        [1]],   \n",
    "        ]\n",
    ")\n",
    "\n",
    "c = np.linspace(start= 0, stop= 1, num= N_AGENTS)      # c_i are chosen uniformly from [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4000000000000001\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(sum(P[:, 0, 0])) # expect to see 1.4\n",
    "\n",
    "print(sum(b[:, 0, 0])) # expect to see 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `f_global`\n",
    "\n",
    "$f_{global} = 1.4x_1^2 + x_2^2 +  0.9x_1x_1 + 10x_1 + 11x_2 + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_global(x1, x2): \n",
    "    \n",
    "    return sum(P[:, 0, 0]) * x1**2 + sum(P[:, 1, 1]) * x2 ** 2 \\\n",
    "           + ( sum(P[:, 1, 0]) + sum(P[: , 0, 1]) ) * x1 * x2 \\\n",
    "           + sum(b[:, 0, 0]) * x1 + sum(b[:, 1, 0]) * x2 \\\n",
    "           + sum(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find global minima $\\hat{x}_1, \\hat{x}_2$\n",
    "by finding the solutions for first derivative of `f_global = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4000000000000001 1.0 0.9 10 11 c =  2.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(P[:, 0, 0]), sum(P[:, 1, 1]),  ( sum(P[:, 1, 0]) + sum(P[: , 0, 1]) ), sum(b[:, 0, 0]), sum(b[:, 1, 0]), \"c = \", sum(c) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_vector_f_global_Analytic(x):\n",
    "\n",
    "    x1, x2 = x[0], x[1]\n",
    "\n",
    "    return 2 * sum(P[:, 0, 0]) * x1 + ( sum(P[:, 1, 0]) + sum(P[: , 0, 1]) ) * x2 + sum(b[:, 0, 0]), \\\n",
    "           2 * sum(P[:, 1, 1]) * x2 + ( sum(P[:, 1, 0]) + sum(P[: , 0, 1]) ) * x1 + sum(b[:, 1, 0]) \n",
    "\n",
    "def gradient_vector_f_global_Autograd(x):\n",
    "\n",
    "    import jax\n",
    "\n",
    "    x1, x2 = x[0], x[1]\n",
    "\n",
    "    f_partial_x1 = jax.grad(f_global, argnums= 0)\n",
    "    f_partial_x2 = jax.grad(f_global, argnums= 1)\n",
    "\n",
    "    return f_partial_x1(x1, x2), f_partial_x2(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution analytic gradient:  [-2.1085595  -4.55114823]\n",
      "solution autograd:  [-2.10855969 -4.55114813]\n",
      "solution Wolfram:  [-2.1085595  -4.55114823]\n",
      "\n",
      "f_global minimum: analytitc =  -33.5741127348643\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "# def func(x):\n",
    "# \treturn [x[0] * np.cos(x[1]) - 4,\n",
    "# \t\t\tx[1] * x[0] - x[1] - 5]\n",
    "\n",
    "root_analytic = fsolve(gradient_vector_f_global_Analytic, [0, 0])\n",
    "print(\"solution analytic gradient: \", root_analytic)\n",
    "\n",
    "root_autograd = fsolve(gradient_vector_f_global_Autograd, [0., 0.])\n",
    "print(\"solution autograd: \", root_autograd)\n",
    "print(\"solution Wolfram: \", np.array([-1010/479, -2180/479]) )\n",
    "\n",
    "print()\n",
    "print(\"f_global minimum: analytitc = \", f_global(root_analytic[0], root_analytic[1])  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: optimal solution is in fact `[-2.1085595, -4.55114823]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-33.57411273486426\n"
     ]
    }
   ],
   "source": [
    "print( f_global( -2.10855969,  -4.55114813) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3700000000000001\n"
     ]
    }
   ],
   "source": [
    "print(-4.55 - (-4.18))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
