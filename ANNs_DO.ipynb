{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a basic ANN on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import torch  # https://pytorch.org\n",
    "import torchvision  # https://pytorch.org\n",
    "from jaxtyping import Array, Float, Int, PyTree  # https://github.com/google/jaxtyping\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/andrei/Desktop/PROJECT_ELLIS_COMDO/FOLDER_code\")\n",
    "import time\n",
    "import comdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "STEPS = 300\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "SEED = 5678\n",
    "\n",
    "key = jax.random.PRNGKey(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise_data = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    \"MNIST\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=normalise_data,\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting MNIST into 2 balanced, distinct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir(\"/home/andrei/Desktop/PROJECT_ELLIS_COMDO/FOLDER_code\")\n",
    "\n",
    "from comdo.utils_ANNs import get_2DO_datasets\n",
    "\n",
    "\n",
    "Agent1_Train_dataset, Agent1_Test_dataset, Agent2_Train_dataset, Agent2_Test_dataset = \\\n",
    "    get_2DO_datasets(train_dataset= train_dataset, test_dataset= test_dataset)\n",
    "\n",
    "\n",
    "trainloader_Agent1 = torch.utils.data.DataLoader(\n",
    "    Agent1_Train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader_Agent1 = torch.utils.data.DataLoader(\n",
    "    Agent1_Test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "trainloader_Agent2 = torch.utils.data.DataLoader(\n",
    "    Agent2_Train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "testloader_Agent2 = torch.utils.data.DataLoader(\n",
    "    Agent2_Test_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making 2 ANNs with the exact same initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = jax.random.split(key, 4)\n",
    "        # Standard CNN setup: convolutional layer, followed by flattening,\n",
    "        # with a small MLP on top.\n",
    "        self.layers = [\n",
    "            eqx.nn.Conv2d(1, 3, kernel_size=4, key=key1),\n",
    "            eqx.nn.MaxPool2d(kernel_size=2),\n",
    "            jax.nn.relu,\n",
    "            jnp.ravel,\n",
    "            eqx.nn.Linear(1728, 512, key=key2),\n",
    "            jax.nn.sigmoid,\n",
    "            eqx.nn.Linear(512, 64, key=key3),\n",
    "            jax.nn.relu,\n",
    "            eqx.nn.Linear(64, 10, key=key4),\n",
    "            jax.nn.log_softmax,\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: Float[Array, \"1 28 28\"]) -> Float[Array, \"10\"]:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "SEED = 5678\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "key, subkey = jax.random.split(key, 2)\n",
    "\n",
    "agent1 = CNN(subkey)\n",
    "agent2 = CNN(subkey)\n",
    "\n",
    "models = [agent1, agent2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the PyTree - The weights should be equal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do agent 1 and 2 have the same weights in the first layer?\n",
      "True\n",
      "[[[-0.0246132   0.20315117 -0.12337857  0.1912669 ]\n",
      "  [ 0.01224852  0.03098577 -0.17678964  0.18533075]\n",
      "  [-0.00282699 -0.12770635 -0.10529053 -0.24286664]\n",
      "  [-0.05992258  0.18098432 -0.22828996  0.21605003]]]\n",
      "[[[-0.0246132   0.20315117 -0.12337857  0.1912669 ]\n",
      "  [ 0.01224852  0.03098577 -0.17678964  0.18533075]\n",
      "  [-0.00282699 -0.12770635 -0.10529053 -0.24286664]\n",
      "  [-0.05992258  0.18098432 -0.22828996  0.21605003]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Do agent 1 and 2 have the same weights in the first layer?\")\n",
    "print(agent1.layers[0].weight.all() == agent2.layers[0].weight.all())\n",
    "\n",
    "print(agent1.layers[0].weight[0]) # I expect them to be equal\n",
    "print(agent2.layers[0].weight[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def loss(\n",
    "    model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # Our input has the shape (BATCH_SIZE, 1, 28, 28), but our model operations on\n",
    "    # a single input input image of shape (1, 28, 28).\n",
    "    #\n",
    "    # Therefore, we have to use jax.vmap, which in this case maps our model over the\n",
    "    # leading (batch) axis.\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    return cross_entropy(y, pred_y)\n",
    "\n",
    "\n",
    "def cross_entropy(\n",
    "    y: Int[Array, \" batch\"], pred_y: Float[Array, \"batch 10\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    # y are the true targets, and should be integers 0-9.\n",
    "    # pred_y are the log-softmax'd predictions.\n",
    "    pred_y = jnp.take_along_axis(pred_y, jnp.expand_dims(y, 1), axis=1)\n",
    "    return -jnp.mean(pred_y)\n",
    "\n",
    "dummy_x, dummy_y = next(iter(trainloader_Agent1))\n",
    "\n",
    "dummy_x = jnp.array(dummy_x)\n",
    "dummy_y = jnp.array(dummy_y)\n",
    "\n",
    "# Example loss\n",
    "loss_value = loss(agent1, dummy_x, dummy_y)\n",
    "print(loss_value.shape)  # scalar loss\n",
    "# Example inference\n",
    "output = jax.vmap(agent1)(dummy_x)\n",
    "\n",
    "print(output.shape)  # batch of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3517985\n"
     ]
    }
   ],
   "source": [
    "# Getting the parameters\n",
    "\n",
    "value, grads = eqx.filter_value_and_grad(loss)(agent1, dummy_x, dummy_y)\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = eqx.filter_jit(loss)  # JIT our loss function from earlier!\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_accuracy(\n",
    "    model: CNN, x: Float[Array, \"batch 1 28 28\"], y: Int[Array, \" batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    \"\"\"This function takes as input the current model\n",
    "    and computes the average accuracy on a batch.\n",
    "    \"\"\"\n",
    "    pred_y = jax.vmap(model)(x)\n",
    "    pred_y = jnp.argmax(pred_y, axis=1)\n",
    "    return jnp.mean(y == pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: CNN, testloader: torch.utils.data.DataLoader):\n",
    "    \"\"\"This function evaluates the model on the test dataset,\n",
    "    computing both the average loss and the average accuracy.\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    for x, y in testloader:\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        # Note that all the JAX operations happen inside `loss` and `compute_accuracy`,\n",
    "        # and both have JIT wrappers, so this is fast.\n",
    "        avg_loss += loss(model, x, y)\n",
    "        avg_acc += compute_accuracy(model, x, y)\n",
    "    return avg_loss / len(testloader), avg_acc / len(testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(2.3291311, dtype=float32), Array(0.08623417, dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(agent1, testloader_Agent1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3293533325195312\n",
      "<class 'float'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(float(evaluate(models[0], testloader_Agent1)[0]))\n",
    "print(print(type(float(evaluate(models[0], testloader_Agent1)[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from comdo.utils_ANNs import DOptimizer\n",
    "\n",
    "def train(\n",
    "    models: CNN,\n",
    "    trainloader_Agent1: torch.utils.data.DataLoader,\n",
    "    trainloader_Agent2: torch.utils.data.DataLoader,\n",
    "    testloader_Agent1: torch.utils.data.DataLoader,\n",
    "    testloader_Agent2: torch.utils.data.DataLoader,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> CNN:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    # opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    optimizer = comdo.utils_ANNs.DOptimizer(models= models,\n",
    "                                            beta_c = LEARNING_RATE,\n",
    "                                            beta_g = LEARNING_RATE,\n",
    "                                            beta_gm = LEARNING_RATE / 2)                                        \n",
    "\n",
    "    # # Uncomment in case this doesn't work when inside class    \n",
    "    # optimizer.shape_z_g\n",
    "    # optimizer.shape_gradient_memory\n",
    "    # optimizer.gradient_memory\n",
    "    \n",
    "    # optimizer.shape_gradient_memory = [optimizer.n_agents, optimizer.len_memory]\n",
    "    # optimizer.shape_z_g = [optimizer.n_agents]\n",
    "    # optimizer.idx_layersWithWeights = []\n",
    "\n",
    "    # for i in range(len(models[0].layers)):\n",
    "    #     if hasattr(models[0].layers[i], \"weight\"):\n",
    "    #         optimizer.idx_layersWithWeights.append(i)\n",
    "    #         for dim in jnp.shape(models[0].layers[i]):\n",
    "    #             optimizer.shape_gradient_memory.append(dim)\n",
    "    #             optimizer.z_g.append(dim)\n",
    "\n",
    "    print()\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "\n",
    "\n",
    "    # @eqx.filter_jit\n",
    "    def make_step(\n",
    "        models: CNN,\n",
    "        x_agent1: Float[Array, \"batch 1 28 28\"],\n",
    "        y_agent1: Int[Array, \" batch\"],\n",
    "        x_agent2: Float[Array, \"batch 1 28 28\"],\n",
    "        y_agent2: Int[Array, \" batch\"],\n",
    "\n",
    "    ):\n",
    "\n",
    "        # making list with the grads (pytrees) of th etwo agents\n",
    "        grads_list = []\n",
    "        grads_list.append(eqx.filter_value_and_grad(loss)(models[0], x_agent1, y_agent1)[1])\n",
    "        grads_list.append(eqx.filter_value_and_grad(loss)(models[1], x_agent2, y_agent2)[1])\n",
    "\n",
    "        # loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        # updates, opt_state = optim.update(grads, opt_state, model)\n",
    "\n",
    "        # model = eqx.apply_updates(model, updates)\n",
    "        \n",
    "        models = optimizer.step_withMemory(models, grads_list)\n",
    "\n",
    "        return models\n",
    "    \n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader_agent1():\n",
    "        while True:\n",
    "            yield from trainloader_Agent1\n",
    "\n",
    "    def infinite_trainloader_agent2():\n",
    "        while True: \n",
    "            yield from trainloader_Agent2\n",
    "\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for step, (x_agent1, y_agent1), (x_agent2, y_agent2) in zip(range(steps), infinite_trainloader_agent1(), infinite_trainloader_agent2()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x_agent1 = x_agent1.numpy()\n",
    "        y_agent1 = y_agent1.numpy()\n",
    "\n",
    "        x_agent2 = x_agent2.numpy()\n",
    "        y_agent2 = y_agent2.numpy()\n",
    "        \n",
    "        # start = time.time()\n",
    "\n",
    "\n",
    "        models = make_step(models, x_agent1, y_agent1, x_agent2, y_agent2)\n",
    "            \n",
    "        # print(\"Made step \", step )\n",
    "        # print(\"Seconds to take this step: \", time.time() - start)\n",
    "\n",
    "\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            train_loss = 0\n",
    "            train_accuracy = 0\n",
    "\n",
    "            # start = time.time()\n",
    "\n",
    "            test_loss +=  float(evaluate(models[0], testloader_Agent1)[0])\n",
    "            test_accuracy +=  float(evaluate(models[0], testloader_Agent1)[1])\n",
    "            \n",
    "            test_loss += float(evaluate(models[1], testloader_Agent2)[0])\n",
    "            test_accuracy += float(evaluate(models[1], testloader_Agent2)[1])\n",
    "\n",
    "            train_loss +=  float(evaluate(models[0], trainloader_Agent1)[0])\n",
    "            train_accuracy += float(evaluate(models[0], trainloader_Agent1)[1])\n",
    "            train_loss += float(evaluate(models[1], trainloader_Agent2)[0])\n",
    "            train_accuracy += float(evaluate(models[1], trainloader_Agent2)[1])\n",
    "\n",
    "\n",
    "            # print(\"Seconds to compute loss and accuracy: \", time.time() - start)\n",
    "\n",
    "            # start = time.time()\n",
    "\n",
    "            writer.add_scalar(\"global train loss\", train_loss/2, step)   # printing means\n",
    "            writer.add_scalar(\"global test loss\", test_loss/2, step)\n",
    "\n",
    "            writer.add_scalar(\"global train accuracy\", train_accuracy/2, step)\n",
    "            writer.add_scalar(\"global test accuracy\", test_accuracy/2, step)\n",
    "\n",
    "            # if (step % print_every) == 0 or (step == steps - 1):\n",
    "            print(\n",
    "                f\"global train_loss={train_loss/2}, gloabal train_accuracy={train_accuracy/2} \"\n",
    "                f\"global test_loss={test_loss/2}, global test_accuracy={test_accuracy/2}\" )\n",
    "            \n",
    "            \n",
    "            # print(\"Seconds to write and print: \", time.time() - start)\n",
    "\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Made step  0\n",
      "Seconds to take this step:  0.9320087432861328\n",
      "global train_loss=2.3305402994155884, gloabal train_accuracy=0.08047902584075928 global test_loss=2.3268001079559326, global test_accuracy=0.08890426903963089\n",
      "Made step  1\n",
      "Seconds to take this step:  0.701838493347168\n",
      "Made step  2\n",
      "Seconds to take this step:  0.7393503189086914\n",
      "Made step  3\n",
      "Seconds to take this step:  0.7125844955444336\n",
      "Made step  4\n",
      "Seconds to take this step:  0.710456371307373\n",
      "Made step  5\n",
      "Seconds to take this step:  0.7114512920379639\n",
      "Made step  6\n",
      "Seconds to take this step:  0.7384293079376221\n",
      "Made step  7\n",
      "Seconds to take this step:  0.6841535568237305\n",
      "Made step  8\n",
      "Seconds to take this step:  0.6873557567596436\n",
      "Made step  9\n",
      "Seconds to take this step:  0.7093634605407715\n",
      "Made step  10\n",
      "Seconds to take this step:  0.7276513576507568\n",
      "global train_loss=2.1663317680358887, gloabal train_accuracy=0.3602879047393799 global test_loss=2.1595379114151, global test_accuracy=0.3799446225166321\n",
      "Made step  11\n",
      "Seconds to take this step:  0.7055408954620361\n",
      "Made step  12\n",
      "Seconds to take this step:  0.9699985980987549\n",
      "Made step  13\n",
      "Seconds to take this step:  0.6953325271606445\n",
      "Made step  14\n",
      "Seconds to take this step:  0.7039663791656494\n",
      "Made step  15\n",
      "Seconds to take this step:  0.7137529850006104\n",
      "Made step  16\n",
      "Seconds to take this step:  0.7151360511779785\n",
      "Made step  17\n",
      "Seconds to take this step:  0.6986331939697266\n",
      "Made step  18\n",
      "Seconds to take this step:  0.7199127674102783\n",
      "Made step  19\n",
      "Seconds to take this step:  0.7178347110748291\n",
      "Made step  20\n",
      "Seconds to take this step:  0.719921350479126\n",
      "global train_loss=1.9632890820503235, gloabal train_accuracy=0.5775331556797028 global test_loss=1.951292872428894, global test_accuracy=0.584651917219162\n",
      "Made step  21\n",
      "Seconds to take this step:  0.7034487724304199\n",
      "Made step  22\n",
      "Seconds to take this step:  0.7223703861236572\n",
      "Made step  23\n",
      "Seconds to take this step:  0.7131462097167969\n",
      "Made step  24\n",
      "Seconds to take this step:  0.6958718299865723\n",
      "Made step  25\n",
      "Seconds to take this step:  0.7163681983947754\n",
      "Made step  26\n",
      "Seconds to take this step:  0.7031762599945068\n",
      "Made step  27\n",
      "Seconds to take this step:  0.7096612453460693\n",
      "Made step  28\n",
      "Seconds to take this step:  0.738325834274292\n",
      "Made step  29\n",
      "Seconds to take this step:  0.7151894569396973\n",
      "Made step  30\n",
      "Seconds to take this step:  0.7171921730041504\n",
      "global train_loss=1.7229797840118408, gloabal train_accuracy=0.6404122412204742 global test_loss=1.7053524851799011, global test_accuracy=0.6553599834442139\n",
      "Made step  31\n",
      "Seconds to take this step:  0.6656100749969482\n",
      "Made step  32\n",
      "Seconds to take this step:  0.6765182018280029\n",
      "Made step  33\n",
      "Seconds to take this step:  0.6774547100067139\n",
      "Made step  34\n",
      "Seconds to take this step:  0.7139980792999268\n",
      "Made step  35\n",
      "Seconds to take this step:  0.7377378940582275\n",
      "Made step  36\n",
      "Seconds to take this step:  0.7327651977539062\n",
      "Made step  37\n",
      "Seconds to take this step:  0.7359442710876465\n",
      "Made step  38\n",
      "Seconds to take this step:  0.7191348075866699\n",
      "Made step  39\n",
      "Seconds to take this step:  0.7083926200866699\n",
      "Made step  40\n",
      "Seconds to take this step:  0.6999833583831787\n",
      "global train_loss=1.4867545366287231, gloabal train_accuracy=0.7152563631534576 global test_loss=1.4682732224464417, global test_accuracy=0.7262658476829529\n",
      "Made step  41\n",
      "Seconds to take this step:  0.7064368724822998\n",
      "Made step  42\n",
      "Seconds to take this step:  0.7151086330413818\n",
      "Made step  43\n",
      "Seconds to take this step:  0.7035832405090332\n",
      "Made step  44\n",
      "Seconds to take this step:  0.7004384994506836\n",
      "Made step  45\n",
      "Seconds to take this step:  0.7156815528869629\n",
      "Made step  46\n",
      "Seconds to take this step:  0.7128427028656006\n",
      "Made step  47\n",
      "Seconds to take this step:  0.7212746143341064\n",
      "Made step  48\n",
      "Seconds to take this step:  0.7022757530212402\n",
      "Made step  49\n",
      "Seconds to take this step:  0.7136712074279785\n",
      "Made step  50\n",
      "Seconds to take this step:  0.7380030155181885\n",
      "global train_loss=1.2997369766235352, gloabal train_accuracy=0.7126287519931793 global test_loss=1.2735164165496826, global test_accuracy=0.736847311258316\n",
      "Made step  51\n",
      "Seconds to take this step:  0.7058744430541992\n",
      "Made step  52\n",
      "Seconds to take this step:  0.7119872570037842\n",
      "Made step  53\n",
      "Seconds to take this step:  0.7454569339752197\n",
      "Made step  54\n",
      "Seconds to take this step:  0.7002146244049072\n",
      "Made step  55\n",
      "Seconds to take this step:  0.7145226001739502\n",
      "Made step  56\n",
      "Seconds to take this step:  0.7019875049591064\n",
      "Made step  57\n",
      "Seconds to take this step:  0.709345817565918\n",
      "Made step  58\n",
      "Seconds to take this step:  0.9401884078979492\n",
      "Made step  59\n",
      "Seconds to take this step:  0.7331027984619141\n",
      "Made step  60\n",
      "Seconds to take this step:  0.6724159717559814\n",
      "global train_loss=1.1013412475585938, gloabal train_accuracy=0.8106512725353241 global test_loss=1.0753923058509827, global test_accuracy=0.8317840099334717\n",
      "Made step  61\n",
      "Seconds to take this step:  0.7659409046173096\n",
      "Made step  62\n",
      "Seconds to take this step:  0.8220083713531494\n",
      "Made step  63\n",
      "Seconds to take this step:  0.7217745780944824\n",
      "Made step  64\n",
      "Seconds to take this step:  0.8451809883117676\n",
      "Made step  65\n",
      "Seconds to take this step:  0.76690673828125\n",
      "Made step  66\n",
      "Seconds to take this step:  0.7444272041320801\n",
      "Made step  67\n",
      "Seconds to take this step:  0.7464666366577148\n",
      "Made step  68\n",
      "Seconds to take this step:  0.7432928085327148\n",
      "Made step  69\n",
      "Seconds to take this step:  0.7383818626403809\n",
      "Made step  70\n",
      "Seconds to take this step:  0.7674164772033691\n",
      "global train_loss=0.9638582766056061, gloabal train_accuracy=0.8056556582450867 global test_loss=0.9318319857120514, global test_accuracy=0.8204113841056824\n",
      "Made step  71\n",
      "Seconds to take this step:  0.7359504699707031\n",
      "Made step  72\n",
      "Seconds to take this step:  0.6632130146026611\n",
      "Made step  73\n",
      "Seconds to take this step:  0.6716105937957764\n",
      "Made step  74\n",
      "Seconds to take this step:  0.716367244720459\n",
      "Made step  75\n",
      "Seconds to take this step:  0.7097625732421875\n",
      "Made step  76\n",
      "Seconds to take this step:  0.7112278938293457\n",
      "Made step  77\n",
      "Seconds to take this step:  0.7379727363586426\n",
      "Made step  78\n",
      "Seconds to take this step:  0.7308876514434814\n",
      "Made step  79\n",
      "Seconds to take this step:  0.6816980838775635\n",
      "Made step  80\n",
      "Seconds to take this step:  0.7192580699920654\n",
      "global train_loss=0.8552118539810181, gloabal train_accuracy=0.8383624255657196 global test_loss=0.8294685184955597, global test_accuracy=0.8464201092720032\n",
      "Made step  81\n",
      "Seconds to take this step:  0.7161164283752441\n",
      "Made step  82\n",
      "Seconds to take this step:  0.734133243560791\n",
      "Made step  83\n",
      "Seconds to take this step:  0.8306334018707275\n",
      "Made step  84\n",
      "Seconds to take this step:  0.784395694732666\n",
      "Made step  85\n",
      "Seconds to take this step:  0.721182107925415\n",
      "Made step  86\n",
      "Seconds to take this step:  0.7512643337249756\n",
      "Made step  87\n",
      "Seconds to take this step:  0.7332062721252441\n",
      "Made step  88\n",
      "Seconds to take this step:  0.7107944488525391\n",
      "Made step  89\n",
      "Seconds to take this step:  0.8441061973571777\n",
      "Made step  90\n",
      "Seconds to take this step:  0.7268567085266113\n",
      "global train_loss=0.7804096043109894, gloabal train_accuracy=0.8296079933643341 global test_loss=0.7512050867080688, global test_accuracy=0.84375\n",
      "Made step  91\n",
      "Seconds to take this step:  0.7259426116943359\n",
      "Made step  92\n",
      "Seconds to take this step:  0.746140718460083\n",
      "Made step  93\n",
      "Seconds to take this step:  0.7065794467926025\n",
      "Made step  94\n",
      "Seconds to take this step:  0.8076357841491699\n",
      "Made step  95\n",
      "Seconds to take this step:  0.8198251724243164\n",
      "Made step  96\n",
      "Seconds to take this step:  0.7409787178039551\n",
      "Made step  97\n",
      "Seconds to take this step:  0.7358026504516602\n",
      "Made step  98\n",
      "Seconds to take this step:  0.9200646877288818\n",
      "Made step  99\n",
      "Seconds to take this step:  0.7479302883148193\n",
      "Made step  100\n",
      "Seconds to take this step:  0.8194282054901123\n",
      "global train_loss=0.6912668645381927, gloabal train_accuracy=0.8620394468307495 global test_loss=0.6602184474468231, global test_accuracy=0.8758900463581085\n",
      "Made step  101\n",
      "Seconds to take this step:  0.7590868473052979\n",
      "Made step  102\n",
      "Seconds to take this step:  0.7548243999481201\n",
      "Made step  103\n",
      "Seconds to take this step:  0.7493047714233398\n",
      "Made step  104\n",
      "Seconds to take this step:  0.746762752532959\n",
      "Made step  105\n",
      "Seconds to take this step:  0.8038105964660645\n",
      "Made step  106\n",
      "Seconds to take this step:  0.647902250289917\n",
      "Made step  107\n",
      "Seconds to take this step:  0.6767518520355225\n",
      "Made step  108\n",
      "Seconds to take this step:  0.7017440795898438\n",
      "Made step  109\n",
      "Seconds to take this step:  0.6553385257720947\n",
      "Made step  110\n",
      "Seconds to take this step:  0.6597180366516113\n",
      "global train_loss=0.6284500062465668, gloabal train_accuracy=0.872303694486618 global test_loss=0.6005355417728424, global test_accuracy=0.8838014304637909\n",
      "Made step  111\n",
      "Seconds to take this step:  0.6674902439117432\n",
      "Made step  112\n",
      "Seconds to take this step:  0.9246656894683838\n",
      "Made step  113\n",
      "Seconds to take this step:  0.6570560932159424\n",
      "Made step  114\n",
      "Seconds to take this step:  0.664726734161377\n",
      "Made step  115\n",
      "Seconds to take this step:  0.6805214881896973\n",
      "Made step  116\n",
      "Seconds to take this step:  0.7258598804473877\n",
      "Made step  117\n",
      "Seconds to take this step:  0.7221314907073975\n",
      "Made step  118\n",
      "Seconds to take this step:  0.682321310043335\n",
      "Made step  119\n",
      "Seconds to take this step:  0.6523745059967041\n",
      "Made step  120\n",
      "Seconds to take this step:  0.672114372253418\n",
      "global train_loss=0.593042641878128, gloabal train_accuracy=0.8705649673938751 global test_loss=0.5592876374721527, global test_accuracy=0.8829114139080048\n",
      "Made step  121\n",
      "Seconds to take this step:  0.7089672088623047\n",
      "Made step  122\n",
      "Seconds to take this step:  0.6861007213592529\n",
      "Made step  123\n",
      "Seconds to take this step:  0.67022705078125\n",
      "Made step  124\n",
      "Seconds to take this step:  0.7219390869140625\n",
      "Made step  125\n",
      "Seconds to take this step:  0.6693317890167236\n",
      "Made step  126\n",
      "Seconds to take this step:  0.6707038879394531\n",
      "Made step  127\n",
      "Seconds to take this step:  0.6946859359741211\n",
      "Made step  128\n",
      "Seconds to take this step:  0.6725170612335205\n",
      "Made step  129\n",
      "Seconds to take this step:  0.6744425296783447\n",
      "Made step  130\n",
      "Seconds to take this step:  0.6714560985565186\n",
      "global train_loss=0.5440737009048462, gloabal train_accuracy=0.8784132301807404 global test_loss=0.5138912051916122, global test_accuracy=0.8909216821193695\n",
      "Made step  131\n",
      "Seconds to take this step:  0.7078709602355957\n",
      "Made step  132\n",
      "Seconds to take this step:  0.7072744369506836\n",
      "Made step  133\n",
      "Seconds to take this step:  0.6791961193084717\n",
      "Made step  134\n",
      "Seconds to take this step:  0.7051692008972168\n",
      "Made step  135\n",
      "Seconds to take this step:  0.7002432346343994\n",
      "Made step  136\n",
      "Seconds to take this step:  0.657545804977417\n",
      "Made step  137\n",
      "Seconds to take this step:  0.6435213088989258\n",
      "Made step  138\n",
      "Seconds to take this step:  0.6597483158111572\n",
      "Made step  139\n",
      "Seconds to take this step:  0.6783046722412109\n",
      "Made step  140\n",
      "Seconds to take this step:  0.6816577911376953\n",
      "global train_loss=0.5207326710224152, gloabal train_accuracy=0.8792585730552673 global test_loss=0.48699167370796204, global test_accuracy=0.894679605960846\n",
      "Made step  141\n",
      "Seconds to take this step:  0.6354515552520752\n",
      "Made step  142\n",
      "Seconds to take this step:  0.6524543762207031\n",
      "Made step  143\n",
      "Seconds to take this step:  0.7464981079101562\n",
      "Made step  144\n",
      "Seconds to take this step:  0.6872141361236572\n",
      "Made step  145\n",
      "Seconds to take this step:  0.6851358413696289\n",
      "Made step  146\n",
      "Seconds to take this step:  0.6537926197052002\n",
      "Made step  147\n",
      "Seconds to take this step:  0.65264892578125\n",
      "Made step  148\n",
      "Seconds to take this step:  0.6510188579559326\n",
      "Made step  149\n",
      "Seconds to take this step:  0.696303129196167\n",
      "Made step  150\n",
      "Seconds to take this step:  0.6885859966278076\n",
      "global train_loss=0.48859845101833344, gloabal train_accuracy=0.8881107270717621 global test_loss=0.45925813913345337, global test_accuracy=0.9011075794696808\n",
      "Made step  151\n",
      "Seconds to take this step:  0.76273512840271\n",
      "Made step  152\n",
      "Seconds to take this step:  0.7811160087585449\n",
      "Made step  153\n",
      "Seconds to take this step:  0.9770321846008301\n",
      "Made step  154\n",
      "Seconds to take this step:  0.8523311614990234\n",
      "Made step  155\n",
      "Seconds to take this step:  0.9282660484313965\n",
      "Made step  156\n",
      "Seconds to take this step:  0.7543394565582275\n",
      "Made step  157\n",
      "Seconds to take this step:  0.9579885005950928\n",
      "Made step  158\n",
      "Seconds to take this step:  1.0652389526367188\n",
      "Made step  159\n",
      "Seconds to take this step:  0.6397461891174316\n",
      "Made step  160\n",
      "Seconds to take this step:  0.6185734272003174\n",
      "global train_loss=0.46564652025699615, gloabal train_accuracy=0.8894016146659851 global test_loss=0.43482355773448944, global test_accuracy=0.9023931920528412\n",
      "Made step  161\n",
      "Seconds to take this step:  0.7358157634735107\n",
      "Made step  162\n",
      "Seconds to take this step:  0.7656617164611816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader_Agent1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainloader_Agent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader_Agent2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainloader_Agent2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader_Agent1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtestloader_Agent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader_Agent2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtestloader_Agent2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPRINT_EVERY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [11], line 92\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(models, trainloader_Agent1, trainloader_Agent2, testloader_Agent1, testloader_Agent2, steps, print_every)\u001b[0m\n\u001b[1;32m     87\u001b[0m y_agent2 \u001b[38;5;241m=\u001b[39m y_agent2\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     89\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 92\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_agent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_agent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_agent2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_agent2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMade step \u001b[39m\u001b[38;5;124m\"\u001b[39m, step )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeconds to take this step: \u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start)\n",
      "Cell \u001b[0;32mIn [11], line 64\u001b[0m, in \u001b[0;36mtrain.<locals>.make_step\u001b[0;34m(models, x_agent1, y_agent1, x_agent2, y_agent2)\u001b[0m\n\u001b[1;32m     57\u001b[0m grads_list\u001b[38;5;241m.\u001b[39mappend(eqx\u001b[38;5;241m.\u001b[39mfilter_value_and_grad(loss)(models[\u001b[38;5;241m1\u001b[39m], x_agent2, y_agent2)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# updates, opt_state = optim.update(grads, opt_state, model)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# model = eqx.apply_updates(model, updates)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_withMemory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m models\n",
      "File \u001b[0;32m~/Desktop/PROJECT_ELLIS_COMDO/FOLDER_code/comdo/utils_ANNs.py:260\u001b[0m, in \u001b[0;36mDOptimizer.step_withMemory\u001b[0;34m(self, models, grads_list)\u001b[0m\n\u001b[1;32m    256\u001b[0m         aux_tensor \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([ memory_weights[memory_i] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_memory[agent_i][memory_i][layer_i] \u001b[38;5;28;01mfor\u001b[39;00m memory_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen_memory)])\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;66;03m# print( f\"Shape aux_tensor at layer: {layer_i}:\", np.shape(aux_tensor) ) \u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_g[agent_i][layer_i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maux_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# summing over the memory axis\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_agents):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx_layersWithWeights:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "model = train(models= models, trainloader_Agent1= trainloader_Agent1, trainloader_Agent2= trainloader_Agent2, testloader_Agent1= testloader_Agent1, testloader_Agent2= testloader_Agent2, steps= STEPS, print_every= PRINT_EVERY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It takes < 1 second to make a step, but 20 seconds to compute metrics, compute metrics more sparse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It trains! \n",
    "\n",
    "Awesome - I get 0.85 accuracy in 100 iterations;\n",
    "\n",
    "Slow as fuck - for 300 I need 100 minutes;\n",
    "\n",
    "### Plan\n",
    "- put **2h into jit'ing** whatever can be jit'ed\n",
    "- if unsuccessful -> train only for 50 iterations (15 min) (should get 80% acc. )\n",
    "    - for 3 algorithms, 10 runs, 2 conditions with 10 runs each, it should take 15h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gradient_term = jnp.zeros(self.shape_z_g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Centralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: CNN,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> CNN:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: CNN,\n",
    "        opt_state: PyTree,\n",
    "        x: Float[Array, \"batch 1 28 28\"],\n",
    "        y: Int[Array, \" batch\"],\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from trainloader\n",
    "\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "\n",
    "        \n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            test_loss, test_accuracy = evaluate(model, testloader)\n",
    "            train_loss, train_accuracy = evaluate(model, trainloader)\n",
    "\n",
    "            writer.add_scalar(\"train loss\", float(train_loss), step)\n",
    "            writer.add_scalar(\"test loss\", float(test_loss), step)\n",
    "\n",
    "            writer.add_scalar(\"train accuracy\", float(train_accuracy), step)\n",
    "            writer.add_scalar(\"test accuracy\", float(test_accuracy), step)\n",
    "\n",
    "            print(\n",
    "                f\"train_loss={train_loss.item()}, train_accuracy={train_accuracy.item()} \"\n",
    "                f\"test_loss={test_loss.item()}, test_accuracy={test_accuracy.item()}\"\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type loss value\")\n",
    "\n",
    "print(float(evaluate(agent1, testloader_Agent1)[0]))\n",
    "print(type(float(evaluate(agent1, testloader_Agent1)[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [agent1, agent2]\n",
    "\n",
    "def train(\n",
    "    model: CNN,\n",
    "    trainloader: torch.utils.data.DataLoader,\n",
    "    testloader: torch.utils.data.DataLoader,\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int,\n",
    "    print_every: int,\n",
    ") -> CNN:\n",
    "    # Just like earlier: It only makes sense to train the arrays in our model,\n",
    "    # so filter out everything else.\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    # Always wrap everything -- computing gradients, running the optimiser, updating\n",
    "    # the model -- into a single JIT region. This ensures things run as fast as\n",
    "    # possible.\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: CNN,\n",
    "        opt_state: PyTree,\n",
    "        x: Float[Array, \"batch 1 28 28\"],\n",
    "        y: Int[Array, \" batch\"],\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(model, x, y)\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    # Loop over our training dataset as many times as we need.\n",
    "    def infinite_trainloader():\n",
    "        while True:\n",
    "            yield from trainloader\n",
    "\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for step, (x, y) in zip(range(steps), infinite_trainloader()):\n",
    "        # PyTorch dataloaders give PyTorch tensors by default,\n",
    "        # so convert them to NumPy arrays.\n",
    "        x = x.numpy()\n",
    "        y = y.numpy()\n",
    "        model, opt_state, train_loss = make_step(model, opt_state, x, y)\n",
    "    \n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        train_loss = 0\n",
    "        train_accuracy = 0\n",
    "\n",
    "        for model in models:\n",
    "            test_loss, test_accuracy += float(evaluate(model, testloader)[0]), float(evaluate(model, testloader)[1])\n",
    "            train_loss, train_accuracy += float(evaluate(model, trainloader)[0]), float(evaluate(model, trainloader)[1])\n",
    "\n",
    "        writer.add_scalar(\"global train loss\", sum(train_loss)/len(train_loss), step)   # printing means\n",
    "        writer.add_scalar(\"global test loss\", sum(test_loss)/len(test_loss), step)\n",
    "\n",
    "        writer.add_scalar(\"global train accuracy\", sum(train_accuracy)/len(train_accuracy), step)\n",
    "        writer.add_scalar(\"global test accuracy\", sum(test_accuracy)/len(test_accuracy), step)\n",
    "\n",
    "        if (step % print_every) == 0 or (step == steps - 1):\n",
    "            print(\n",
    "                f\"global train_loss={sum(train_loss)}, gloabal train_accuracy={sum(train_accuracy)/len(train_accuracy)} \"\n",
    "                f\"global test_loss={sum(test_loss)}, global test_accuracy={sum(test_accuracy)/len(test_accuracy)}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        optimizer = DOptimizer( models = models,\n",
    "                                fs_private = fs_private,\n",
    "                                len_memory = len(models),\n",
    "                                memory_len = memory_len,\n",
    "                                beta_c = beta_c,\n",
    "                                beta_g = beta_g,\n",
    "                                beta_gm = beta_gm)\n",
    "\n",
    "        grads_list = []\n",
    "        for model in models:\n",
    "            grads_list.append(eqx.filter_value_and_grad(loss)(model, x, y)[1])\n",
    "        \n",
    "        model = optimizer.step_withMemory(models, grads_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "\n",
    "\n",
    "optim = optax.adamw(LEARNING_RATE)\n",
    "\n",
    "print(optax.adamw(LEARNING_RATE).update.__globals__)\n",
    "\n",
    "optax.adam(LEARNING_RATE).update()\n",
    "\n",
    "model = train(model, trainloader, testloader, optim, STEPS, PRINT_EVERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optax.adam({\"e\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archive\n",
    "\n",
    "- 0.38 loss - 3.5 min\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "\n",
    "STEPS = 300\n",
    "\n",
    "PRINT_EVERY = 30\n",
    "\n",
    "SEED = 5678\n",
    "\n",
    "\n",
    "- fucked\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 3e-2\n",
    "\n",
    "STEPS = 300\n",
    "\n",
    "PRINT_EVERY = 30\n",
    "\n",
    "SEED = 5678\n",
    "\n",
    "\n",
    "- 0.38 loss\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 2*3e-4\n",
    "\n",
    "STEPS = 300\n",
    "\n",
    "PRINT_EVERY = 30\n",
    "\n",
    "SEED = 5678\n",
    "\n",
    "\n",
    "- 0.15 loss\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.005\n",
    "\n",
    "STEPS = 300\n",
    "\n",
    "PRINT_EVERY = 30\n",
    "\n",
    "SEED = 5678"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
