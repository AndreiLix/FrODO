# FrODO: Fractional Order Distributed Optimization
(see in paper form: https://arxiv.org/abs/2412.02546)

Buiding an ML optimizer with competitve performance by integrating a computational neuroscience model into stochastic gradient descent.

Implementation of the algorithm is found in `FOLDER_code/comdo/utils_proper.py`.

Main outcomes of the project:

### Achieved stability across objectives with ill-defined Hessian matrices
![image](https://github.com/AndreiLix/FrODO/assets/94043928/e54c963f-bc52-49a8-9397-c190bcc62b61)


### Achieved competitive performance with state of the art when scaling up to Federated Learning 
![image](https://github.com/AndreiLix/FrODO/assets/94043928/e668dc2e-0fa7-401f-a09a-d51c5f843f1f)
